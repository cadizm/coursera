
Anomaly Detection
=================


### Problem Motivation

1. x(i) = features dataset

2. model p(x) from data

3. identify unusual/anomalous examples where p(example) < some epsilon


### Gaussian (Normal) distribution

~ means "distributed as"

gaussian probability distribution given fixed mu/sigma:

    p(x; mu, sigma^2)

mu = mean
variance = sigma^2
standard deviation = sigma


### Formula for estimating parameters mu and sigma^2

    mu = 1/m * (summation i=1 to m, x(i))

    sigma^2 = 1/m * (summation i=1 to m, (x(i) - u)^2)


### Anomaly Detection Algorithm

1. Choose features x(i) that you think might be indicative of anomalous
   examples

2. Fit parameters u-1, ..., u-n, sigma-1^2, ..., sigma-n^2

       u-j = 1/m * summation(i=1 to m of x-j-i)

       sigma-j^2 = 1/m * summation(i=1 to m of (x-j-i - u-j)^2)

3. Given new example x, compute p(x):

       p(x) = product(j=1 to n of p(x-j; u-j; sigma-j^2)) =

       product(j=1 to n of 1/(sqrt(2 * pi) * sigma-j) * exp(-((x-j - u-j)^2 / (2 * sigma-j^2))))

4. Anomaly if p(x) < some epsilon


### Developing/Evaluating an Anomaly Detection System

Given we have fit a model p(x), when evaluating the cross validation or test sets,
classification accuracy is not a good way to measure performance because of skewed
classes (so an algorithm that always predicts y=0 will have high accuracy)

Possible evaluation metrics:

  - true positive, false positive, false negative, true negative

  - precision/recall

  - F1 score

Can also use cross validation set to choose parameter epsilon


### Anomaly Detection vs Supervised Learning

Anomaly detection

  - very small number of positive examples (y=1) (0-20 common)

  - large number of negative examples (y=0)

  - fraud dection, manufacturing, monitoring machines

Supervised learning

  - large number of positive and negative examples

  - email spam classification, weather prediction, cancer classification


### Choosing What Features to Use

Choose features that have a gaussian distribution or use transformations to
make data more gaussian

Error analysis for anomaly detection

  Want p(x) large for normal examples x
       p(x) small for anomalous examples x

Most common problem is p(x) is similar for both normal and anomalous examples

What is most likely to help is coming up with more features to distinguish
between the normal and anomalous examples


Recommender Systems
===================

n-u =  number of users

n-m = number of movies

r(i, j) = 1 if user j has rated movie i, 0 otherwise

y(i, j) rating given by user j to movie i (defined iff r(i, j) = 1)


### Content Based Recommendations

Treat each user as a linear regression problem: for each user j, learn a
parameter theta(j) in R. Predict user j as rating movie i with:

  theta(j)' * x(i) stars


### Collaborative Filtering


