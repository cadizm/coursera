
Octave Tutorial
===============

### Basic operations

`%` => comment
~=  => not equal
`;` => suppress output

### Commands

`disp` => display
`format` => format display
`hist` => histogram
`diary [on][off][FILENAME]` =>

### Sample session

```
% Create row vector from 1 to 2 inclusive stepping by 0.1
v = 1:0.1:2

octave:10> ones(2, 3)
ans =

   1   1   1
   1   1   1

octave:11> 2 * ones(2, 3)
ans =

   2   2   2
   2   2   2


octave:12> w = rand(3, 3)
w =

   0.19242   0.54459   0.98690
   0.16111   0.63883   0.43769
   0.90684   0.37054   0.98313


% gaussian distribution
octave:13> w = randn(3, 3)
w =

   1.75410   0.29540  -0.14692
  -1.26684  -0.14497  -1.81311
   0.27506  -1.34062   0.86325

octave:18> w = -6 + sqrt(10) * (randn(1, 1000));
octave:19> hist(w) % plot histogram

octave:22> eye(4)
ans =

Diagonal Matrix

   1   0   0   0
   0   1   0   0
   0   0   1   0
   0   0   0   1

octave:25> help help
```

### Moving data around

```
octave:1> A = [1 2; 3 4; 5 6]
A =

   1   2
   3   4
   5   6

octave:2> sz = size(A)
sz =

   3   2

octave:3> size(sz)
ans =

   1   2

% rows
octave:4> size(A, 1)
ans =  3

% columns
octave:5> size(A, 2)
ans =  2

```


Multivariate Linear Regression
==============================

x1, x2, x3 => features
y = output
n = number of features
x(i) = input (features) of ith training exmaple
x(i)(j) = value of feature j in ith training example

### Linear Regression in Practice
  * feature scaling
  * feature "mean normalization"

x = original value
x' = normalized value

x' = (x - avg(x)) / (max(x) - min(x))

[feature scaling](https://en.wikipedia.org/wiki/Feature_scaling)

If gradient descent is not converging, your learning rate
alpha may be too large.

Find out whether it is converging by graphing j(theta) vs
number of iterations, which should decrease at after every
iteration given sufficiently small alpha.

Summary
  * alpha too small: slow convergence
  * alpha too large: J(theta) may not decrease every iteration;
                     may not converge
  * plat J(theta) vs # of iterations

To choose alpha, try 3-fold increases:
0.003, 0.03, 0.3, 3, ...
